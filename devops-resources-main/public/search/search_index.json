{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Devops in Action - Guide For each step you have a TD to discover the subject and a TP to put it into practice. The TPs follow each other and the goal is to make you start from a local application and get to an application delivered in production and accessible to all. For that we will give you each a server and a Java application. Part 1 - Docker session Docker TDs are available here Docker TPs are available here Docker slides are available here Part 2 - Github Action session Github Actions TDs are available here Github Actions TPs are available here Github Actions slides are availabe here Please read the indications carefully, most of the time what you need is in front of your eyes! \u00a9 Takima 2023","title":"Devops in Action - Guide"},{"location":"#devops-in-action-guide","text":"For each step you have a TD to discover the subject and a TP to put it into practice. The TPs follow each other and the goal is to make you start from a local application and get to an application delivered in production and accessible to all. For that we will give you each a server and a Java application. Part 1 - Docker session Docker TDs are available here Docker TPs are available here Docker slides are available here Part 2 - Github Action session Github Actions TDs are available here Github Actions TPs are available here Github Actions slides are availabe here Please read the indications carefully, most of the time what you need is in front of your eyes! \u00a9 Takima 2023","title":"Devops in Action - Guide"},{"location":"ch1-discover-docker-td/","text":"Discover Docker Note Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time) Question Point to document/report Tip Interesting information Setup Prerequisites There are no specific skills needed for this tutorial beyond a basic comfort with the command line and using a text editor. Prior experience in developing web applications will be helpful but is not required. As you proceed further along the tutorial, we'll make use of https://cloud.docker.com/. Setting up your computer Getting all the tooling setup on your computer can be a daunting task, but getting Docker up and running on your favorite OS has become very easy. The getting started guide on Docker has detailed instructions for setting up Docker on Mac, Linux and Windows If you're using Docker for Windows make sure you have shared your drive. Important note If you're using an older version of Windows or MacOS you may need to use Docker Machine instead. All commands work in either bash or Powershell on Windows Once you are done installing Docker, test your Docker installation by running the following: docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 03f4658f8b78: Pull complete a3ed95caeb02: Pull complete Digest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7 Status: Downloaded newer image for hello-world:latest Hello from Docker. ... This message shows that your installation appears to be working correctly. Running your first container Now that you have everything setup, it's time to get our hands dirty. In this section, you are going to run an Alpine Linux container (a lightweight linux distribution) on your system and get a taste of the docker run command. To get started, let's run the following in our terminal: $ docker pull alpine Note Depending on how you've installed docker on your system, you might see a permission denied error after running the above command. Try the commands from the Getting Started tutorial to verify your installation . If you're on Linux, you may need to prefix your docker commands with sudo . Alternatively you can create a docker group to get rid of this issue. The pull command fetches the alpine image from the Docker registry and saves it in our system. You can use the docker images command to see a list of all images on your system. $ docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE alpine latest c51f86c28340 4 weeks ago 1 .109 MB hello-world latest 690ed74de00f 5 months ago 960 B 1.1 Docker Run Great! Let's now run a Docker container based on this image. To do that you are going to use the docker run command. $ docker run alpine ls -l total 48 drwxr-xr-x 2 root root 4096 Mar 2 16:20 bin drwxr-xr-x 5 root root 360 Mar 18 09:47 dev drwxr-xr-x 13 root root 4096 Mar 18 09:47 etc drwxr-xr-x 2 root root 4096 Mar 2 16:20 home drwxr-xr-x 5 root root 4096 Mar 2 16:20 lib ...... ...... What happened? Behind the scenes, a lot of stuff happened. When you call run : 1. The Docker client contacts the Docker daemon. The Docker daemon checks local store if the image (alpine in this case) is available locally, and if not, downloads it from Docker Store. (Since we have issued docker pull alpine before, the download step is not necessary) The Docker daemon creates the container and then runs a command in that container. The Docker daemon streams the output of the command to the Docker client When you run docker run alpine , you provided a command ( ls -l ), so Docker started the command specified and you saw the listing. Let's try something more exciting. $ docker run alpine echo \"hello from alpine\" hello from alpine OK, that's some actual output. In this case, the Docker client dutifully ran the echo command in our alpine container and then exited it. If you've noticed, all of that happened pretty quickly. Imagine booting up a virtual machine, running a command and then killing it. Now you know why they say containers are fast! Try another command. $ docker run alpine /bin/sh Wait, nothing happened! Is that a bug? Well, no. These interactive shells will exit after running any scripted commands, unless they are run in an interactive terminal - so for this example to not exit, you need to docker run -it alpine /bin/sh . You are now inside the container shell and you can try out a few commands like ls -l , uname -a and others. Exit out of the container by giving the exit command. Ok, now it's time to see the docker ps command. The docker ps command shows you all containers that are currently running. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Since no containers are running, you see a blank line. Let's try a more useful variant: docker ps -a $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 36171a5da744 alpine \"/bin/sh\" 5 minutes ago Exited ( 0 ) 2 minutes ago fervent_newton a6a9d46d0b2f alpine \"echo 'hello from alp\" 6 minutes ago Exited ( 0 ) 6 minutes ago lonely_kilby ff0a5c3750b9 alpine \"ls -l\" 8 minutes ago Exited ( 0 ) 8 minutes ago elated_ramanujan c317d0a9e3d2 hello-world \"/hello\" 34 seconds ago Exited ( 0 ) 12 minutes ago stupefied_mcclintock What you see above is a list of all containers that you ran. Notice that the STATUS column shows that these containers exited a few minutes ago. You're probably wondering if there is a way to run more than just one command in a container. Let's try that now: $ docker run -it alpine /bin/sh / # ls bin dev etc home lib linuxrc media mnt proc root run sbin sys tmp usr var / # uname -a Linux 97916e8cb5dc 4.4.27-moby #1 SMP Wed Oct 26 14:01:48 UTC 2016 x86_64 Linux Running the run command with the -it flags attaches us to an interactive tty in the container. Now you can run as many commands in the container as you want. Take some time to run your favorite commands. Tip run -it is a very useful command to debug at the lowest level a container. That concludes a whirlwind tour of the docker run command which would most likely be the command you'll use most often. It makes sense to spend some time getting comfortable with it. To find out more about run , use docker run --help to see a list of all flags it supports. As you proceed further, we'll see a few more variants of docker run. 1.2 Terminology In the last section, you saw a lot of Docker-specific jargon which might be confusing to some. So before you go further, let's clarify some terminology that is used frequently in the Docker ecosystem. Images - The file system and configuration of our application which are used to create containers. To find out more about a Docker image, run docker inspect alpine . In the demo above, you used the docker pull command to download the alpine image. When you executed the command docker run hello-world , it also did a docker pull behind the scenes to download the hello-world image. Containers - Running instances of Docker images \u2014 containers run the actual applications. A container includes an application and all of its dependencies. It shares the kernel with other containers, and runs as an isolated process in user space on the host OS. You created a container using docker run which you did using the alpine image that you downloaded. A list of running containers can be seen using the docker ps command. Docker daemon - The background service running on the host that manages building, running and distributing Docker containers. Docker client - The command line tool that allows the user to interact with the Docker daemon. Docker Store - A registry of Docker images, where you can find trusted and enterprise ready containers, plugins, and Docker editions. You'll be using this later in this tutorial. 2.0 Webapps with Docker Great! So you have now looked at docker run , played with a Docker container and also got the hang of some terminology. Armed with all this knowledge, you are now ready to get to the real stuff \u2014 deploying web applications with Docker. 2.1 Run a static website in a container Note Code for this section is in this repo in the static-site directory Let's start by taking baby-steps. First, we'll use Docker to run a static website in a container. The website is based on an existing image. We'll pull a Docker image from Docker Store, run the container, and see how easy it is to set up a web server. The image that you are going to use is a single-page website that was already created for this demo and is available on the Docker Store as dockersamples/static-site . You can download and run the image directly in one go using docker run as follows. $ docker run -d dockersamples/static-site Note The current version of this image doesn't run without the -d flag. The -d flag enables detached mode, which detaches the running container from the terminal/shell and returns your prompt after the container starts. We are debugging the problem with this image but for now, use -d even for this first example. Tip -d is a very useful option. So, what happens when you run this command? Since the image doesn't exist on your Docker host, the Docker daemon first fetches it from the registry and then runs it as a container. Now that the server is running, do you see the website? What port is it running on? And more importantly, how do you access the container directly from our host machine? Actually, you probably won't be able to answer any of these questions yet! \u263a In this case, the client didn't tell the Docker Engine to publish any of the ports, so you need to re-run the docker run command to add this instruction. Let's re-run the command with some new flags to publish ports and pass your name to the container to customize the message displayed. We'll use the -d option again to run the container in detached mode. First, stop the container that you have just launched. In order to do this, we need the container ID. Since we ran the container in detached mode, we don't have to launch another terminal to do this. Run docker ps to view the running containers. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a7a0e504ca3e dockersamples/static-site \"/bin/sh -c 'cd /usr/\" 28 seconds ago Up 26 seconds 80 /tcp, 443 /tcp stupefied_mahavira Check out the CONTAINER ID column. You will need to use this CONTAINER ID value, a long sequence of characters, to identify the container you want to stop, and then to remove it. The example below provides the CONTAINER ID on our system; you should use the value that you see in your terminal. $ docker stop a7a0e504ca3e $ docker rm a7a0e504ca3e Note A cool feature is that you do not need to specify the entire CONTAINER ID . You can just specify a few starting characters and if it is unique among all the containers that you have launched, the Docker client will intelligently pick it up. Now, let's launch a container in detached mode as shown below: $ docker run --name static-site -e AUTHOR = \"Your Name\" -d -P dockersamples/static-site e61d12292d69556eabe2a44c16cbd54486b2527e2ce4f95438e504afb7b02810 In the above command: -d will create a container with the process detached from our terminal -P will publish all the exposed container ports to random ports on the Docker host -e is how you pass environment variables to the container. --name allows you to specify a container name AUTHOR is the environment variable name and Your Name is the value that you can pass. Now you can see the ports by running the docker port command. $ docker port static-site 443 /tcp -> 0 .0.0.0:32772 80 /tcp -> 0 .0.0.0:32773 If you are running Docker for Mac, Docker for Windows, or Docker on Linux, you can open http://localhost:[YOUR_PORT_FOR 80/tcp] . For our example this is http://localhost:32773 . You can now open http://localhost:[YOUR_PORT_FOR 80/tcp] to see your site live! For our example, this is: http://192.168.99.100:32773 . You can also run a second webserver at the same time, specifying a custom host port mapping to the container's webserver. $ docker run --name static-site-2 -e AUTHOR = \"Your Name\" -d -p 8888 :80 dockersamples/static-site To deploy this on a real server you would just need to install Docker, and run the above docker command (as in this case you can see the AUTHOR is Docker which we passed as an environment variable). Now that you've seen how to run a webserver inside a Docker container, how do you create your own Docker image? This is the question we'll explore in the next section. But first, let's stop and remove the containers since you won't be using them anymore. $ docker stop static-site $ docker rm static-site Let's use a shortcut to remove the second site: $ docker rm -f static-site-2 Tip rm -f is a very useful option Run docker ps to make sure the containers are gone. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2.2 Docker Images In this section, let's dive deeper into what Docker images are. You will build your own image, use that image to run an application locally, and finally, push some of your own images to Docker Cloud. Docker images are the basis of containers. In the previous example, you pulled the dockersamples/static-site image from the. registry and asked the Docker client to run a container based on that image. To see the list of images that are available locally on your system, run the docker images command. $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE dockersamples/static-site latest 92a386b6e686 2 hours ago 190 .5 MB nginx latest af4b3d7d5401 3 hours ago 190 .5 MB python 2 .7 1c32174fd534 14 hours ago 676 .8 MB postgres 9 .4 88d845ac7a88 14 hours ago 263 .6 MB containous/traefik latest 27b4e0c6b2fd 4 days ago 20 .75 MB node 0 .10 42426a5cba5f 6 days ago 633 .7 MB redis latest 4f5f397d4b7c 7 days ago 177 .5 MB mongo latest 467eb21035a8 7 days ago 309 .7 MB alpine 3 .3 70c557e50ed6 8 days ago 4 .794 MB java 7 21f6ce84e43c 8 days ago 587 .7 MB Above is a list of images that I've pulled from the registry and those I've created myself (we'll shortly see how). You will have a different list of images on your machine. The TAG refers to a particular snapshot of the image and the ID is the corresponding unique identifier for that image. For simplicity, you can think of an image akin to a git repository - images can be committed with changes and have multiple. versions. When you do not provide a specific version number, the client defaults to latest. For example you could pull a specific version of ubuntu image as follows: $ docker pull ubuntu:12.04 If you do not specify the version number of the image then, as mentioned, the Docker client will default to a version named latest . So for example, the docker pull command given below will pull an image named ubuntu:latest : $ docker pull ubuntu To get a new Docker image you can either get it from a registry (such as the Docker Store) or create your own. There are hundreds of thousands of images available on Docker Store . You can also search for images directly from the command line using docker search . An important distinction with regard to images is between base images and child images . Base images are images that have no parent images, usually images with an OS like ubuntu, alpine or debian. Child images are images that build on base images and add additional functionality. Another key concept is the idea of official images and user images. (Both of which can be base images or child images.) Official images are Docker sanctioned images. Docker, Inc. sponsors a dedicated team that is responsible for reviewing and publishing all Official Repositories content. This team works in collaboration with upstream software maintainers, security experts, and the broader Docker community. These are not prefixed by an organization or user name. In the list of images above, the python , node , alpine and nginx images are official (base) images. To find out more about them, check out the Official Images Documentation . User images are images created and shared by users like you. They build on base images and add additional functionality. Typically these are formatted as user/image-name . The user value in the image name is your Docker Store user or organization name. 2.3 Create your first image Now that you have a better understanding of images, it's time to create your own. Our main objective here is to create an image that sandboxes a small Flask application. The goal of this exercise is to create a Docker image which will run a Flask app. We'll do this by first pulling together the components for a random cat picture generator built with Python Flask, then dockerizing it by writing a Dockerfile . Finally, we'll build the image, and then run it. 2.3.1 Create a Python Flask app that displays random cat pix. For the purposes of this workshop, we've created a fun little Python Flask app that displays a random cat .gif every time it is loaded - because, you know, who doesn't like cats? Start by creating a directory called flask-app where we'll create the following files: app.py requirements.txt templates/index.html Dockerfile Make sure to cd flask-app before you start creating the files, because you don't want to start adding a whole bunch of other random files to your image. app.py Create the app.py with the following content: from flask import Flask , render_template import random app = Flask ( __name__ ) # list of cat images images = [ \"https://c.tenor.com/GTcT7HODLRgAAAAM/smiling-cat-creepy-cat.gif\" , \"https://media0.giphy.com/media/10dU7AN7xsi1I4/giphy.webp?cid=ecf05e47gk63rd81vzlot57qmebr7drtgf6a3khmzvjsdtu7&rid=giphy.webp&ct=g\" , \"https://media0.giphy.com/media/S6VGjvmFRu5Qk/giphy.webp?cid=ecf05e478yofpawrhffnnvb3sgjkos96vyfo5mtqhds35as6&rid=giphy.webp&ct=g\" , \"https://media3.giphy.com/media/JIX9t2j0ZTN9S/200w.webp?cid=ecf05e47gk63rd81vzlot57qmebr7drtgf6a3khmzvjsdtu7&rid=200w.webp&ct=g\" ] @app . route ( '/' ) def index (): url = random . choice ( images ) return render_template ( 'index.html' , url = url ) if __name__ == \"__main__\" : app . run ( host = \"0.0.0.0\" ) requirements.txt In order to install the Python modules required for our app, we need to create a file called requirements.txt and add the following line to that file: Flask==0.10.1 templates/index.html Create a directory called templates and create an index.html file in that directory with the following content in it: < html > < head > < style type = \"text/css\" > body { background : black ; color : white ; } div . container { max-width : 500 px ; margin : 100 px auto ; border : 20 px solid white ; padding : 10 px ; text-align : center ; } h4 { text-transform : uppercase ; } </ style > </ head > < body > < div class = \"container\" > < h4 > Cat Gif of the day </ h4 > < img src = \"{{url}}\" /> < p >< small > Courtesy: < a href = \"http://www.buzzfeed.com/copyranter/the-best-cat-gif-post-in-the-history-of-cat-gifs\" > Buzzfeed </ a ></ small ></ p > </ div > </ body > </ html > 2.3.2 Write a Dockerfile We want to create a Docker image with this web app. As mentioned above, all user images are based on a base image. Since our application is written in Python, we will build our own Python image based on Alpine . We'll do that using a Dockerfile. A Dockerfile is a text file that contains a list of commands that the Docker daemon calls while creating an image. The Dockerfile contains all the information that Docker needs to know to run the app \u2014 a base Docker image to run from, location of your project code, any dependencies it has, and what commands to run at start-up. It is a simple way to automate the image creation process. The best part is that the commands you write in a Dockerfile are almost identical to their equivalent Linux commands. This means you don't really have to learn new syntax to create your own Dockerfiles. Create a file called Dockerfile, and add content to it as described below. We'll start by specifying our base image, using the FROM keyword: FROM alpine:3.6 The next step usually is to write the commands of copying the files and installing the dependencies. But first we will install the Python pip package to the alpine linux distribution. This will not just install the pip package but any other dependencies too, which includes the python interpreter. Add the following RUN command next: RUN apk add --update py2-pip Let's add the files that make up the Flask Application. Install all Python requirements for our app to run. This will be accomplished by adding the lines: COPY requirements.txt /usr/src/app/ RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt Copy the files you have created earlier into our image by using COPY command. COPY app.py /usr/src/app/ COPY templates/index.html /usr/src/app/templates/ Specify the port number which needs to be exposed. Since our flask app is running on 5000 that's what we'll expose. EXPOSE 5000 The last step is the command for running the application which is simply - python ./app.py . Use the CMD command to do that: CMD [ \"python\" , \"/usr/src/app/app.py\" ] The primary purpose of CMD is to tell the container which command it should run by default when it is started. Verify your Dockerfile. Our Dockerfile is now ready. This is how it looks: # our base image FROM alpine:3.6 # Install python and pip RUN apk add --update py2-pip # install Python modules needed by the Python app COPY requirements.txt /usr/src/app/ RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt # copy files required for the app to run COPY app.py /usr/src/app/ COPY templates/index.html /usr/src/app/templates/ # tell the port number the container should expose EXPOSE 5000 # run the application CMD [ \"python\" , \"/usr/src/app/app.py\" ] 2.3.3 Build the image Now that you have your Dockerfile , you can build your image. The docker build command does the heavy-lifting of creating a docker image from a Dockerfile . When you run the docker build command given below, make sure to replace <YOUR_USERNAME> with your username. This username should be the same one you created when registering on Docker Cloud . If you haven't done that yet, please go ahead and create an account. The docker build command is quite simple - it takes an optional tag name with the -t flag, and the location of the directory containing the Dockerfile - the . indicates the current directory: $ docker build -t <YOUR_USERNAME>/myfirstapp . Sending build context to Docker daemon 9 .728 kB Step 1 : FROM alpine:latest ---> 0d81fc72e790 Step 2 : RUN apk add --update py-pip ---> Running in 8abd4091b5f5 fetch http://dl-4.alpinelinux.org/alpine/v3.3/main/x86_64/APKINDEX.tar.gz fetch http://dl-4.alpinelinux.org/alpine/v3.3/community/x86_64/APKINDEX.tar.gz ( 1 /12 ) Installing libbz2 ( 1 .0.6-r4 ) ( 2 /12 ) Installing expat ( 2 .1.0-r2 ) ( 3 /12 ) Installing libffi ( 3 .2.1-r2 ) ( 4 /12 ) Installing gdbm ( 1 .11-r1 ) ( 5 /12 ) Installing ncurses-terminfo-base ( 6 .0-r6 ) ( 6 /12 ) Installing ncurses-terminfo ( 6 .0-r6 ) ( 7 /12 ) Installing ncurses-libs ( 6 .0-r6 ) ( 8 /12 ) Installing readline ( 6 .3.008-r4 ) ( 9 /12 ) Installing sqlite-libs ( 3 .9.2-r0 ) ( 10 /12 ) Installing python ( 2 .7.11-r3 ) ( 11 /12 ) Installing py-setuptools ( 18 .8-r0 ) ( 12 /12 ) Installing py-pip ( 7 .1.2-r0 ) Executing busybox-1.24.1-r7.trigger OK: 59 MiB in 23 packages ---> 976a232ac4ad Removing intermediate container 8abd4091b5f5 Step 3 : COPY requirements.txt /usr/src/app/ ---> 65b4be05340c Removing intermediate container 29ef53b58e0f Step 4 : RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt ---> Running in a1f26ded28e7 Collecting Flask == 0 .10.1 ( from -r /usr/src/app/requirements.txt ( line 1 )) Downloading Flask-0.10.1.tar.gz ( 544kB ) Collecting Werkzeug> = 0 .7 ( from Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading Werkzeug-0.11.4-py2.py3-none-any.whl ( 305kB ) Collecting Jinja2> = 2 .4 ( from Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading Jinja2-2.8-py2.py3-none-any.whl ( 263kB ) Collecting itsdangerous> = 0 .21 ( from Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading itsdangerous-0.24.tar.gz ( 46kB ) Collecting MarkupSafe ( from Jinja2> = 2 .4->Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading MarkupSafe-0.23.tar.gz Installing collected packages: Werkzeug, MarkupSafe, Jinja2, itsdangerous, Flask Running setup.py install for MarkupSafe Running setup.py install for itsdangerous Running setup.py install for Flask Successfully installed Flask-0.10.1 Jinja2-2.8 MarkupSafe-0.23 Werkzeug-0.11.4 itsdangerous-0.24 You are using pip version 7 .1.2, however version 8 .1.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ---> 8de73b0730c2 Removing intermediate container a1f26ded28e7 Step 5 : COPY app.py /usr/src/app/ ---> 6a3436fca83e Removing intermediate container d51b81a8b698 Step 6 : COPY templates/index.html /usr/src/app/templates/ ---> 8098386bee99 Removing intermediate container b783d7646f83 Step 7 : EXPOSE 5000 ---> Running in 31401b7dea40 ---> 5e9988d87da7 Removing intermediate container 31401b7dea40 Step 8 : CMD python /usr/src/app/app.py ---> Running in 78e324d26576 ---> 2f7357a0805d Removing intermediate container 78e324d26576 Successfully built 2f7357a0805d If you don't have the alpine:3.6 image, the client will first pull the image and then create your image. Therefore, your output on running the command will look different from mine. If everything went well, your image should be ready! Run docker images and see if your image ( <YOUR_USERNAME>/myfirstapp ) shows. 2.3.4 Run your image The next step in this section is to run the image and see if it actually works. $ docker run -p 8888 :5000 --name myfirstapp YOUR_USERNAME/myfirstapp * Running on http://0.0.0.0:5000/ ( Press CTRL+C to quit ) Head over to http://localhost:8888 and your app should be live. Note If you are using Docker Machine, you may need to open up another terminal and determine the container ip address using docker-machine ip default . Hit the Refresh button in the web browser to see a few more cat images. 2.3.4 Dockerfile commands summary Here's a quick summary of the few basic commands we used in our Dockerfile. FROM starts the Dockerfile. It is a requirement that the Dockerfile must start with the FROM command. Images are created in layers, which means you can use another image as the base image for your own. The FROM command defines your base layer. As arguments, it takes the name of the image. Optionally, you can add the Docker Cloud username of the maintainer and image version, in the format username/imagename:version . RUN is used to build up the Image you're creating. For each RUN command, Docker will run the command then create a new layer of the image. This way you can roll back your image to previous states easily. The syntax for a RUN instruction is to place the full text of the shell command after the RUN (e.g., RUN mkdir /user/local/foo ). This will automatically run in a /bin/sh shell. You can define a different shell like this: RUN /bin/bash -c 'mkdir /user/local/foo ' COPY copies local files into the container. CMD defines the commands that will run on the Image at start-up. Unlike a RUN , this does not create a new layer for the Image, but simply runs the command. There can only be one CMD per a Dockerfile/Image. If you need to run multiple commands, the best way to do that is to have the CMD run a script. CMD requires that you tell it where to run the command, unlike RUN . So example CMD commands would be: CMD [ \"python\" , \"./app.py\" ] CMD [ \"/bin/bash\" , \"echo\" , \"Hello World\" ] EXPOSE creates a hint for users of an image which ports provide services. It is included in the information which can be retrieved via $ docker inspect <container-id> . Note The EXPOSE command does not actually make any ports accessible to the host! Instead, this requires publishing ports by means of the -p flag when using $ docker run . Note If you want to learn more about Dockerfiles, check out Best practices for writing Dockerfiles . (source: https://github.com/docker/labs/tree/master/beginner) Now that you know how to run docker container and create Dockerfiles let\u2019s move on to the practical part.","title":"TD part 01 - Docker"},{"location":"ch1-discover-docker-td/#discover-docker","text":"Note Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time) Question Point to document/report Tip Interesting information","title":"Discover Docker"},{"location":"ch1-discover-docker-td/#setup","text":"","title":"Setup"},{"location":"ch1-discover-docker-td/#prerequisites","text":"There are no specific skills needed for this tutorial beyond a basic comfort with the command line and using a text editor. Prior experience in developing web applications will be helpful but is not required. As you proceed further along the tutorial, we'll make use of https://cloud.docker.com/.","title":"Prerequisites"},{"location":"ch1-discover-docker-td/#setting-up-your-computer","text":"Getting all the tooling setup on your computer can be a daunting task, but getting Docker up and running on your favorite OS has become very easy. The getting started guide on Docker has detailed instructions for setting up Docker on Mac, Linux and Windows If you're using Docker for Windows make sure you have shared your drive. Important note If you're using an older version of Windows or MacOS you may need to use Docker Machine instead. All commands work in either bash or Powershell on Windows Once you are done installing Docker, test your Docker installation by running the following: docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 03f4658f8b78: Pull complete a3ed95caeb02: Pull complete Digest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7 Status: Downloaded newer image for hello-world:latest Hello from Docker. ... This message shows that your installation appears to be working correctly.","title":"Setting up your computer"},{"location":"ch1-discover-docker-td/#running-your-first-container","text":"Now that you have everything setup, it's time to get our hands dirty. In this section, you are going to run an Alpine Linux container (a lightweight linux distribution) on your system and get a taste of the docker run command. To get started, let's run the following in our terminal: $ docker pull alpine Note Depending on how you've installed docker on your system, you might see a permission denied error after running the above command. Try the commands from the Getting Started tutorial to verify your installation . If you're on Linux, you may need to prefix your docker commands with sudo . Alternatively you can create a docker group to get rid of this issue. The pull command fetches the alpine image from the Docker registry and saves it in our system. You can use the docker images command to see a list of all images on your system. $ docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE alpine latest c51f86c28340 4 weeks ago 1 .109 MB hello-world latest 690ed74de00f 5 months ago 960 B","title":"Running your first container"},{"location":"ch1-discover-docker-td/#11-docker-run","text":"Great! Let's now run a Docker container based on this image. To do that you are going to use the docker run command. $ docker run alpine ls -l total 48 drwxr-xr-x 2 root root 4096 Mar 2 16:20 bin drwxr-xr-x 5 root root 360 Mar 18 09:47 dev drwxr-xr-x 13 root root 4096 Mar 18 09:47 etc drwxr-xr-x 2 root root 4096 Mar 2 16:20 home drwxr-xr-x 5 root root 4096 Mar 2 16:20 lib ...... ...... What happened? Behind the scenes, a lot of stuff happened. When you call run : 1. The Docker client contacts the Docker daemon. The Docker daemon checks local store if the image (alpine in this case) is available locally, and if not, downloads it from Docker Store. (Since we have issued docker pull alpine before, the download step is not necessary) The Docker daemon creates the container and then runs a command in that container. The Docker daemon streams the output of the command to the Docker client When you run docker run alpine , you provided a command ( ls -l ), so Docker started the command specified and you saw the listing. Let's try something more exciting. $ docker run alpine echo \"hello from alpine\" hello from alpine OK, that's some actual output. In this case, the Docker client dutifully ran the echo command in our alpine container and then exited it. If you've noticed, all of that happened pretty quickly. Imagine booting up a virtual machine, running a command and then killing it. Now you know why they say containers are fast! Try another command. $ docker run alpine /bin/sh Wait, nothing happened! Is that a bug? Well, no. These interactive shells will exit after running any scripted commands, unless they are run in an interactive terminal - so for this example to not exit, you need to docker run -it alpine /bin/sh . You are now inside the container shell and you can try out a few commands like ls -l , uname -a and others. Exit out of the container by giving the exit command. Ok, now it's time to see the docker ps command. The docker ps command shows you all containers that are currently running. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Since no containers are running, you see a blank line. Let's try a more useful variant: docker ps -a $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 36171a5da744 alpine \"/bin/sh\" 5 minutes ago Exited ( 0 ) 2 minutes ago fervent_newton a6a9d46d0b2f alpine \"echo 'hello from alp\" 6 minutes ago Exited ( 0 ) 6 minutes ago lonely_kilby ff0a5c3750b9 alpine \"ls -l\" 8 minutes ago Exited ( 0 ) 8 minutes ago elated_ramanujan c317d0a9e3d2 hello-world \"/hello\" 34 seconds ago Exited ( 0 ) 12 minutes ago stupefied_mcclintock What you see above is a list of all containers that you ran. Notice that the STATUS column shows that these containers exited a few minutes ago. You're probably wondering if there is a way to run more than just one command in a container. Let's try that now: $ docker run -it alpine /bin/sh / # ls bin dev etc home lib linuxrc media mnt proc root run sbin sys tmp usr var / # uname -a Linux 97916e8cb5dc 4.4.27-moby #1 SMP Wed Oct 26 14:01:48 UTC 2016 x86_64 Linux Running the run command with the -it flags attaches us to an interactive tty in the container. Now you can run as many commands in the container as you want. Take some time to run your favorite commands. Tip run -it is a very useful command to debug at the lowest level a container. That concludes a whirlwind tour of the docker run command which would most likely be the command you'll use most often. It makes sense to spend some time getting comfortable with it. To find out more about run , use docker run --help to see a list of all flags it supports. As you proceed further, we'll see a few more variants of docker run.","title":"1.1 Docker Run"},{"location":"ch1-discover-docker-td/#12-terminology","text":"In the last section, you saw a lot of Docker-specific jargon which might be confusing to some. So before you go further, let's clarify some terminology that is used frequently in the Docker ecosystem. Images - The file system and configuration of our application which are used to create containers. To find out more about a Docker image, run docker inspect alpine . In the demo above, you used the docker pull command to download the alpine image. When you executed the command docker run hello-world , it also did a docker pull behind the scenes to download the hello-world image. Containers - Running instances of Docker images \u2014 containers run the actual applications. A container includes an application and all of its dependencies. It shares the kernel with other containers, and runs as an isolated process in user space on the host OS. You created a container using docker run which you did using the alpine image that you downloaded. A list of running containers can be seen using the docker ps command. Docker daemon - The background service running on the host that manages building, running and distributing Docker containers. Docker client - The command line tool that allows the user to interact with the Docker daemon. Docker Store - A registry of Docker images, where you can find trusted and enterprise ready containers, plugins, and Docker editions. You'll be using this later in this tutorial.","title":"1.2 Terminology"},{"location":"ch1-discover-docker-td/#20-webapps-with-docker","text":"Great! So you have now looked at docker run , played with a Docker container and also got the hang of some terminology. Armed with all this knowledge, you are now ready to get to the real stuff \u2014 deploying web applications with Docker.","title":"2.0 Webapps with Docker"},{"location":"ch1-discover-docker-td/#21-run-a-static-website-in-a-container","text":"Note Code for this section is in this repo in the static-site directory Let's start by taking baby-steps. First, we'll use Docker to run a static website in a container. The website is based on an existing image. We'll pull a Docker image from Docker Store, run the container, and see how easy it is to set up a web server. The image that you are going to use is a single-page website that was already created for this demo and is available on the Docker Store as dockersamples/static-site . You can download and run the image directly in one go using docker run as follows. $ docker run -d dockersamples/static-site Note The current version of this image doesn't run without the -d flag. The -d flag enables detached mode, which detaches the running container from the terminal/shell and returns your prompt after the container starts. We are debugging the problem with this image but for now, use -d even for this first example. Tip -d is a very useful option. So, what happens when you run this command? Since the image doesn't exist on your Docker host, the Docker daemon first fetches it from the registry and then runs it as a container. Now that the server is running, do you see the website? What port is it running on? And more importantly, how do you access the container directly from our host machine? Actually, you probably won't be able to answer any of these questions yet! \u263a In this case, the client didn't tell the Docker Engine to publish any of the ports, so you need to re-run the docker run command to add this instruction. Let's re-run the command with some new flags to publish ports and pass your name to the container to customize the message displayed. We'll use the -d option again to run the container in detached mode. First, stop the container that you have just launched. In order to do this, we need the container ID. Since we ran the container in detached mode, we don't have to launch another terminal to do this. Run docker ps to view the running containers. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a7a0e504ca3e dockersamples/static-site \"/bin/sh -c 'cd /usr/\" 28 seconds ago Up 26 seconds 80 /tcp, 443 /tcp stupefied_mahavira Check out the CONTAINER ID column. You will need to use this CONTAINER ID value, a long sequence of characters, to identify the container you want to stop, and then to remove it. The example below provides the CONTAINER ID on our system; you should use the value that you see in your terminal. $ docker stop a7a0e504ca3e $ docker rm a7a0e504ca3e Note A cool feature is that you do not need to specify the entire CONTAINER ID . You can just specify a few starting characters and if it is unique among all the containers that you have launched, the Docker client will intelligently pick it up. Now, let's launch a container in detached mode as shown below: $ docker run --name static-site -e AUTHOR = \"Your Name\" -d -P dockersamples/static-site e61d12292d69556eabe2a44c16cbd54486b2527e2ce4f95438e504afb7b02810 In the above command: -d will create a container with the process detached from our terminal -P will publish all the exposed container ports to random ports on the Docker host -e is how you pass environment variables to the container. --name allows you to specify a container name AUTHOR is the environment variable name and Your Name is the value that you can pass. Now you can see the ports by running the docker port command. $ docker port static-site 443 /tcp -> 0 .0.0.0:32772 80 /tcp -> 0 .0.0.0:32773 If you are running Docker for Mac, Docker for Windows, or Docker on Linux, you can open http://localhost:[YOUR_PORT_FOR 80/tcp] . For our example this is http://localhost:32773 . You can now open http://localhost:[YOUR_PORT_FOR 80/tcp] to see your site live! For our example, this is: http://192.168.99.100:32773 . You can also run a second webserver at the same time, specifying a custom host port mapping to the container's webserver. $ docker run --name static-site-2 -e AUTHOR = \"Your Name\" -d -p 8888 :80 dockersamples/static-site To deploy this on a real server you would just need to install Docker, and run the above docker command (as in this case you can see the AUTHOR is Docker which we passed as an environment variable). Now that you've seen how to run a webserver inside a Docker container, how do you create your own Docker image? This is the question we'll explore in the next section. But first, let's stop and remove the containers since you won't be using them anymore. $ docker stop static-site $ docker rm static-site Let's use a shortcut to remove the second site: $ docker rm -f static-site-2 Tip rm -f is a very useful option Run docker ps to make sure the containers are gone. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES","title":"2.1 Run a static website in a container"},{"location":"ch1-discover-docker-td/#22-docker-images","text":"In this section, let's dive deeper into what Docker images are. You will build your own image, use that image to run an application locally, and finally, push some of your own images to Docker Cloud. Docker images are the basis of containers. In the previous example, you pulled the dockersamples/static-site image from the. registry and asked the Docker client to run a container based on that image. To see the list of images that are available locally on your system, run the docker images command. $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE dockersamples/static-site latest 92a386b6e686 2 hours ago 190 .5 MB nginx latest af4b3d7d5401 3 hours ago 190 .5 MB python 2 .7 1c32174fd534 14 hours ago 676 .8 MB postgres 9 .4 88d845ac7a88 14 hours ago 263 .6 MB containous/traefik latest 27b4e0c6b2fd 4 days ago 20 .75 MB node 0 .10 42426a5cba5f 6 days ago 633 .7 MB redis latest 4f5f397d4b7c 7 days ago 177 .5 MB mongo latest 467eb21035a8 7 days ago 309 .7 MB alpine 3 .3 70c557e50ed6 8 days ago 4 .794 MB java 7 21f6ce84e43c 8 days ago 587 .7 MB Above is a list of images that I've pulled from the registry and those I've created myself (we'll shortly see how). You will have a different list of images on your machine. The TAG refers to a particular snapshot of the image and the ID is the corresponding unique identifier for that image. For simplicity, you can think of an image akin to a git repository - images can be committed with changes and have multiple. versions. When you do not provide a specific version number, the client defaults to latest. For example you could pull a specific version of ubuntu image as follows: $ docker pull ubuntu:12.04 If you do not specify the version number of the image then, as mentioned, the Docker client will default to a version named latest . So for example, the docker pull command given below will pull an image named ubuntu:latest : $ docker pull ubuntu To get a new Docker image you can either get it from a registry (such as the Docker Store) or create your own. There are hundreds of thousands of images available on Docker Store . You can also search for images directly from the command line using docker search . An important distinction with regard to images is between base images and child images . Base images are images that have no parent images, usually images with an OS like ubuntu, alpine or debian. Child images are images that build on base images and add additional functionality. Another key concept is the idea of official images and user images. (Both of which can be base images or child images.) Official images are Docker sanctioned images. Docker, Inc. sponsors a dedicated team that is responsible for reviewing and publishing all Official Repositories content. This team works in collaboration with upstream software maintainers, security experts, and the broader Docker community. These are not prefixed by an organization or user name. In the list of images above, the python , node , alpine and nginx images are official (base) images. To find out more about them, check out the Official Images Documentation . User images are images created and shared by users like you. They build on base images and add additional functionality. Typically these are formatted as user/image-name . The user value in the image name is your Docker Store user or organization name.","title":"2.2 Docker Images"},{"location":"ch1-discover-docker-td/#23-create-your-first-image","text":"Now that you have a better understanding of images, it's time to create your own. Our main objective here is to create an image that sandboxes a small Flask application. The goal of this exercise is to create a Docker image which will run a Flask app. We'll do this by first pulling together the components for a random cat picture generator built with Python Flask, then dockerizing it by writing a Dockerfile . Finally, we'll build the image, and then run it.","title":"2.3 Create your first image"},{"location":"ch1-discover-docker-td/#231-create-a-python-flask-app-that-displays-random-cat-pix","text":"For the purposes of this workshop, we've created a fun little Python Flask app that displays a random cat .gif every time it is loaded - because, you know, who doesn't like cats? Start by creating a directory called flask-app where we'll create the following files: app.py requirements.txt templates/index.html Dockerfile Make sure to cd flask-app before you start creating the files, because you don't want to start adding a whole bunch of other random files to your image.","title":"2.3.1 Create a Python Flask app that displays random cat pix."},{"location":"ch1-discover-docker-td/#apppy","text":"Create the app.py with the following content: from flask import Flask , render_template import random app = Flask ( __name__ ) # list of cat images images = [ \"https://c.tenor.com/GTcT7HODLRgAAAAM/smiling-cat-creepy-cat.gif\" , \"https://media0.giphy.com/media/10dU7AN7xsi1I4/giphy.webp?cid=ecf05e47gk63rd81vzlot57qmebr7drtgf6a3khmzvjsdtu7&rid=giphy.webp&ct=g\" , \"https://media0.giphy.com/media/S6VGjvmFRu5Qk/giphy.webp?cid=ecf05e478yofpawrhffnnvb3sgjkos96vyfo5mtqhds35as6&rid=giphy.webp&ct=g\" , \"https://media3.giphy.com/media/JIX9t2j0ZTN9S/200w.webp?cid=ecf05e47gk63rd81vzlot57qmebr7drtgf6a3khmzvjsdtu7&rid=200w.webp&ct=g\" ] @app . route ( '/' ) def index (): url = random . choice ( images ) return render_template ( 'index.html' , url = url ) if __name__ == \"__main__\" : app . run ( host = \"0.0.0.0\" )","title":"app.py"},{"location":"ch1-discover-docker-td/#requirementstxt","text":"In order to install the Python modules required for our app, we need to create a file called requirements.txt and add the following line to that file: Flask==0.10.1","title":"requirements.txt"},{"location":"ch1-discover-docker-td/#templatesindexhtml","text":"Create a directory called templates and create an index.html file in that directory with the following content in it: < html > < head > < style type = \"text/css\" > body { background : black ; color : white ; } div . container { max-width : 500 px ; margin : 100 px auto ; border : 20 px solid white ; padding : 10 px ; text-align : center ; } h4 { text-transform : uppercase ; } </ style > </ head > < body > < div class = \"container\" > < h4 > Cat Gif of the day </ h4 > < img src = \"{{url}}\" /> < p >< small > Courtesy: < a href = \"http://www.buzzfeed.com/copyranter/the-best-cat-gif-post-in-the-history-of-cat-gifs\" > Buzzfeed </ a ></ small ></ p > </ div > </ body > </ html >","title":"templates/index.html"},{"location":"ch1-discover-docker-td/#232-write-a-dockerfile","text":"We want to create a Docker image with this web app. As mentioned above, all user images are based on a base image. Since our application is written in Python, we will build our own Python image based on Alpine . We'll do that using a Dockerfile. A Dockerfile is a text file that contains a list of commands that the Docker daemon calls while creating an image. The Dockerfile contains all the information that Docker needs to know to run the app \u2014 a base Docker image to run from, location of your project code, any dependencies it has, and what commands to run at start-up. It is a simple way to automate the image creation process. The best part is that the commands you write in a Dockerfile are almost identical to their equivalent Linux commands. This means you don't really have to learn new syntax to create your own Dockerfiles. Create a file called Dockerfile, and add content to it as described below. We'll start by specifying our base image, using the FROM keyword: FROM alpine:3.6 The next step usually is to write the commands of copying the files and installing the dependencies. But first we will install the Python pip package to the alpine linux distribution. This will not just install the pip package but any other dependencies too, which includes the python interpreter. Add the following RUN command next: RUN apk add --update py2-pip Let's add the files that make up the Flask Application. Install all Python requirements for our app to run. This will be accomplished by adding the lines: COPY requirements.txt /usr/src/app/ RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt Copy the files you have created earlier into our image by using COPY command. COPY app.py /usr/src/app/ COPY templates/index.html /usr/src/app/templates/ Specify the port number which needs to be exposed. Since our flask app is running on 5000 that's what we'll expose. EXPOSE 5000 The last step is the command for running the application which is simply - python ./app.py . Use the CMD command to do that: CMD [ \"python\" , \"/usr/src/app/app.py\" ] The primary purpose of CMD is to tell the container which command it should run by default when it is started. Verify your Dockerfile. Our Dockerfile is now ready. This is how it looks: # our base image FROM alpine:3.6 # Install python and pip RUN apk add --update py2-pip # install Python modules needed by the Python app COPY requirements.txt /usr/src/app/ RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt # copy files required for the app to run COPY app.py /usr/src/app/ COPY templates/index.html /usr/src/app/templates/ # tell the port number the container should expose EXPOSE 5000 # run the application CMD [ \"python\" , \"/usr/src/app/app.py\" ]","title":"2.3.2 Write a Dockerfile"},{"location":"ch1-discover-docker-td/#233-build-the-image","text":"Now that you have your Dockerfile , you can build your image. The docker build command does the heavy-lifting of creating a docker image from a Dockerfile . When you run the docker build command given below, make sure to replace <YOUR_USERNAME> with your username. This username should be the same one you created when registering on Docker Cloud . If you haven't done that yet, please go ahead and create an account. The docker build command is quite simple - it takes an optional tag name with the -t flag, and the location of the directory containing the Dockerfile - the . indicates the current directory: $ docker build -t <YOUR_USERNAME>/myfirstapp . Sending build context to Docker daemon 9 .728 kB Step 1 : FROM alpine:latest ---> 0d81fc72e790 Step 2 : RUN apk add --update py-pip ---> Running in 8abd4091b5f5 fetch http://dl-4.alpinelinux.org/alpine/v3.3/main/x86_64/APKINDEX.tar.gz fetch http://dl-4.alpinelinux.org/alpine/v3.3/community/x86_64/APKINDEX.tar.gz ( 1 /12 ) Installing libbz2 ( 1 .0.6-r4 ) ( 2 /12 ) Installing expat ( 2 .1.0-r2 ) ( 3 /12 ) Installing libffi ( 3 .2.1-r2 ) ( 4 /12 ) Installing gdbm ( 1 .11-r1 ) ( 5 /12 ) Installing ncurses-terminfo-base ( 6 .0-r6 ) ( 6 /12 ) Installing ncurses-terminfo ( 6 .0-r6 ) ( 7 /12 ) Installing ncurses-libs ( 6 .0-r6 ) ( 8 /12 ) Installing readline ( 6 .3.008-r4 ) ( 9 /12 ) Installing sqlite-libs ( 3 .9.2-r0 ) ( 10 /12 ) Installing python ( 2 .7.11-r3 ) ( 11 /12 ) Installing py-setuptools ( 18 .8-r0 ) ( 12 /12 ) Installing py-pip ( 7 .1.2-r0 ) Executing busybox-1.24.1-r7.trigger OK: 59 MiB in 23 packages ---> 976a232ac4ad Removing intermediate container 8abd4091b5f5 Step 3 : COPY requirements.txt /usr/src/app/ ---> 65b4be05340c Removing intermediate container 29ef53b58e0f Step 4 : RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt ---> Running in a1f26ded28e7 Collecting Flask == 0 .10.1 ( from -r /usr/src/app/requirements.txt ( line 1 )) Downloading Flask-0.10.1.tar.gz ( 544kB ) Collecting Werkzeug> = 0 .7 ( from Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading Werkzeug-0.11.4-py2.py3-none-any.whl ( 305kB ) Collecting Jinja2> = 2 .4 ( from Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading Jinja2-2.8-py2.py3-none-any.whl ( 263kB ) Collecting itsdangerous> = 0 .21 ( from Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading itsdangerous-0.24.tar.gz ( 46kB ) Collecting MarkupSafe ( from Jinja2> = 2 .4->Flask == 0 .10.1->-r /usr/src/app/requirements.txt ( line 1 )) Downloading MarkupSafe-0.23.tar.gz Installing collected packages: Werkzeug, MarkupSafe, Jinja2, itsdangerous, Flask Running setup.py install for MarkupSafe Running setup.py install for itsdangerous Running setup.py install for Flask Successfully installed Flask-0.10.1 Jinja2-2.8 MarkupSafe-0.23 Werkzeug-0.11.4 itsdangerous-0.24 You are using pip version 7 .1.2, however version 8 .1.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ---> 8de73b0730c2 Removing intermediate container a1f26ded28e7 Step 5 : COPY app.py /usr/src/app/ ---> 6a3436fca83e Removing intermediate container d51b81a8b698 Step 6 : COPY templates/index.html /usr/src/app/templates/ ---> 8098386bee99 Removing intermediate container b783d7646f83 Step 7 : EXPOSE 5000 ---> Running in 31401b7dea40 ---> 5e9988d87da7 Removing intermediate container 31401b7dea40 Step 8 : CMD python /usr/src/app/app.py ---> Running in 78e324d26576 ---> 2f7357a0805d Removing intermediate container 78e324d26576 Successfully built 2f7357a0805d If you don't have the alpine:3.6 image, the client will first pull the image and then create your image. Therefore, your output on running the command will look different from mine. If everything went well, your image should be ready! Run docker images and see if your image ( <YOUR_USERNAME>/myfirstapp ) shows.","title":"2.3.3 Build the image"},{"location":"ch1-discover-docker-td/#234-run-your-image","text":"The next step in this section is to run the image and see if it actually works. $ docker run -p 8888 :5000 --name myfirstapp YOUR_USERNAME/myfirstapp * Running on http://0.0.0.0:5000/ ( Press CTRL+C to quit ) Head over to http://localhost:8888 and your app should be live. Note If you are using Docker Machine, you may need to open up another terminal and determine the container ip address using docker-machine ip default . Hit the Refresh button in the web browser to see a few more cat images.","title":"2.3.4 Run your image"},{"location":"ch1-discover-docker-td/#234-dockerfile-commands-summary","text":"Here's a quick summary of the few basic commands we used in our Dockerfile. FROM starts the Dockerfile. It is a requirement that the Dockerfile must start with the FROM command. Images are created in layers, which means you can use another image as the base image for your own. The FROM command defines your base layer. As arguments, it takes the name of the image. Optionally, you can add the Docker Cloud username of the maintainer and image version, in the format username/imagename:version . RUN is used to build up the Image you're creating. For each RUN command, Docker will run the command then create a new layer of the image. This way you can roll back your image to previous states easily. The syntax for a RUN instruction is to place the full text of the shell command after the RUN (e.g., RUN mkdir /user/local/foo ). This will automatically run in a /bin/sh shell. You can define a different shell like this: RUN /bin/bash -c 'mkdir /user/local/foo ' COPY copies local files into the container. CMD defines the commands that will run on the Image at start-up. Unlike a RUN , this does not create a new layer for the Image, but simply runs the command. There can only be one CMD per a Dockerfile/Image. If you need to run multiple commands, the best way to do that is to have the CMD run a script. CMD requires that you tell it where to run the command, unlike RUN . So example CMD commands would be: CMD [ \"python\" , \"./app.py\" ] CMD [ \"/bin/bash\" , \"echo\" , \"Hello World\" ] EXPOSE creates a hint for users of an image which ports provide services. It is included in the information which can be retrieved via $ docker inspect <container-id> . Note The EXPOSE command does not actually make any ports accessible to the host! Instead, this requires publishing ports by means of the -p flag when using $ docker run . Note If you want to learn more about Dockerfiles, check out Best practices for writing Dockerfiles . (source: https://github.com/docker/labs/tree/master/beginner) Now that you know how to run docker container and create Dockerfiles let\u2019s move on to the practical part.","title":"2.3.4 Dockerfile commands summary"},{"location":"ch1-discover-docker-tp/","text":"Discover Docker Check Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time). Question Point to document/report. Tip Interesting information. Goals Good practice Do not forget to document what you do along the steps, the documentation provided will be evaluated as your report. Create an appropriate file structure, 1 folder per image. Target application 3-tiers application: HTTP server Backend API Database For each of those applications, we will follow the same process: choose the appropriate docker base image, create and configure this image, put our application specifics inside and at some point have it running. Our final goal is to have a 3-tier web API running. Base images HTTP server Backend API Database Database Basics We will use the image: postgres:14.1-alpine. Let\u2019s have a simple postgres server running, here is what would be a minimal Dockerfile: FROM postgres:14.1-alpine ENV POSTGRES_DB = db \\ POSTGRES_USER = usr \\ POSTGRES_PASSWORD = pwd Build this image and start a container properly, you should be able to access your database depending on the port binding you choose: localhost:PORT. Your Postgres DB should be up and running. Connect to your database and check that everything is running smoothly. Don\u2019t forget to name your docker image and container. Tip If you have difficulties go back to part 2.3.3 Build the image and 2.3.4 Run your image on TD01 - Docker ( TD 1 Discover Docker ). Re-run your database and adminer with --network app-network to enable adminer/database communication. We use -\u2013network instead of -\u2013link because the latter is deprecated. Also, does it seem right to have passwords written in plain text in a file? You may rather define those environment parameters when running the image using the flag -e . Tip Why should we run the container with a flag -e to give the environment variables? Init database Tip Don't forget to create your network docker network create app-network It would be nice to have our database structure initialized with the docker image as well as some initial data. Any sql scripts found in /docker-entrypoint-initdb.d will be executed in alphabetical order, therefore let\u2019s add a couple scripts to our image: Tip Don't forget to restart the adminer: docker run \\ -p \"8090:8080\" \\ --net = app-network \\ --name = adminer \\ -d \\ adminer 01-CreateScheme.sql CREATE TABLE public . departments ( id SERIAL PRIMARY KEY , name VARCHAR ( 20 ) NOT NULL ); CREATE TABLE public . students ( id SERIAL PRIMARY KEY , department_id INT NOT NULL REFERENCES departments ( id ), first_name VARCHAR ( 20 ) NOT NULL , last_name VARCHAR ( 20 ) NOT NULL ); 02-InsertData.sql INSERT INTO departments ( name ) VALUES ( 'IRC' ); INSERT INTO departments ( name ) VALUES ( 'ETI' ); INSERT INTO departments ( name ) VALUES ( 'CGP' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 1 , 'Eli' , 'Copter' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 2 , 'Emma' , 'Carena' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 2 , 'Jack' , 'Uzzi' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 3 , 'Aude' , 'Javel' ); Rebuild your image and check that your scripts have been executed at startup and that the data is present in your container. Tip When we talk about /docker-entrypoint-initdb.d it means inside the container, so you have to copy your directory's content and the container\u2019s directory. Persist data You may have noticed that if your database container gets destroyed then all your data is reset, a database must persist data durably. Use volumes to persist data on the host disk. -v /my/own/datadir:/var/lib/postgresql/data Check that data survives when your container gets destroyed. Link Docker volumes Tip Why do we need a volume to be attached to our postgres container? Question 1-1 Document your database container essentials: commands and Dockerfile. Backend API Basics For starters, we will simply run a Java hello-world class in our containers, only after will we be running a jar. In both cases, choose the proper image keeping in mind that we only need a Java runtime . Here is a complex Java Hello World implementation: Main.java public class Main { public static void main ( String [] args ) { System . out . println ( \"Hello World!\" ); } } 1- Compile with your target Java: javac Main.java . 2- Write dockerfile. FROM # TODO: Choose a java JRE # TODO: Add the compiled java (aka bytecode, aka .class) # TODO: Run the Java with: \u201cjava Main\u201d command. 3- Now, to launch app you have to do the same thing that Basic step 1. Here you have a first glimpse of your backend application. In the next step we will simply enrich the build (using maven instead of a minimalistic javac) and execute a jar instead of a simple .class. \u2192 If it\u2019s a success you must see \u201cHello Word\u201d in your console. Multistage build In the previous section we were building Java code on our machine to have it running on a docker container. Wouldn\u2019t it be great to have Docker handle the build as well? You probably noticed that the default openjdk docker images contain... Well... a JDK! Create a multistage build using the Multistage . Your Dockerfile should look like this: FROM openjdk:11 # Build Main.java # TODO : in next steps (not now) FROM openjdk:11-jre # Copy resource from previous stage COPY --from = 0 /usr/src/Main.class . # Run java code with the JRE # TODO : in next steps (not now) Don\u2019t fill the Dockerfile now, we will have to do it in the next steps. Backend simple api We will deploy a Springboot application providing a simple API with a single greeting endpoint. Create your Springboot application on: Spring Initializer . Use the following config: Project: Maven Language: Java 17 Spring Boot: 2.7.5 Packaging: Jar Dependencies: Spring Web Generate the project and give it a simple GreetingController class: package fr.takima.training.simpleapi.controller ; import org.springframework.web.bind.annotation.* ; import java.util.concurrent.atomic.AtomicLong ; @RestController public class GreetingController { private static final String template = \"Hello, %s!\" ; private final AtomicLong counter = new AtomicLong (); @GetMapping ( \"/\" ) public Greeting greeting ( @RequestParam ( value = \"name\" , defaultValue = \"World\" ) String name ) { return new Greeting ( counter . incrementAndGet (), String . format ( template , name )); } class Greeting { private final long id ; private final String content ; public Greeting ( long id , String content ) { this . id = id ; this . content = content ; } public long getId () { return id ; } public String getContent () { return content ; } } } You can now build and start your application, of course you will need maven and a jdk-17. How convenient would it be to have a virtual container to build and run our simplistic API? Oh wait, we have docker, here is how you could build and run your application with Docker: # Build FROM maven:3.8.6-amazoncorretto-17 AS myapp-build ENV MYAPP_HOME /opt/myapp WORKDIR $MYAPP_HOME COPY pom.xml . COPY src ./src RUN mvn package -DskipTests # Run FROM amazoncorretto:17 ENV MYAPP_HOME /opt/myapp WORKDIR $MYAPP_HOME COPY --from = myapp-build $MYAPP_HOME /target/*.jar $MYAPP_HOME /myapp.jar ENTRYPOINT java -jar myapp.jar Question 1-2 Why do we need a multistage build? And explain each step of this dockerfile. Check A working Springboot application with a simple HelloWorld endpoint. Did you notice that maven downloads all libraries on every image build? You can contribute to saving the planet caching libraries when maven pom file has not been changed by running the goal: mvn dependency:go-offline . Backend API Let\u2019s now build and run the backend API connected to the database. You can get the zipped source code here: simple-api . Adjust the configuration in simple-api/src/main/resources/application.yml (this is the application configuration). How to access the database container from your backend application? Use the deprecated --link or create a docker network . Once everything is properly bound, you should be able to access your application API, for example on: /departments/IRC/students . [ { \"id\" : 1 , \"firstname\" : \"Eli\" , \"lastname\" : \"Copter\" , \"department\" : { \"id\" : 1 , \"name\" : \"IRC\" } } ] Explore your API other endpoints, have a look at the controllers in the source code. Check A simple web API on top of your database. Http server Basics Choose an appropriate base image. Create a simple landing page: index.html and put it inside your container. It should be enough for now, start your container and check that everything is working as expected. Here are commands that you may want to try to do so: docker stats docker inspect docker logs Link Httpd Getting Started Configuration You are using the default apache configuration, and it will be enough for now, you use yours by copying it in your image. Use docker exec to retrieve this default configuration from your running container /usr/local/apache2/conf/httpd.conf . Note You can also use docker cp . Reverse proxy We will configure the http server as a simple reverse proxy server in front of our application, this server could be used to deliver a front-end application, to configure SSL or to handle load balancing. So this can be quite useful even though in our case we will keep things simple. Here is the documentation: Reverse Proxy . Add the following to the configuration, and you should be all set: ServerName localhost <VirtualHost *:80> ProxyPreserveHost On ProxyPass / http://YOUR_BACKEND_LINK:8080/ ProxyPassReverse / http://YOUR_BACKEND_LINK:8080/ </VirtualHost> Tip Why do we need a reverse proxy? Notes Checkpoint: a working application through a reverse proxy. Link application Docker-compose 1- Install docker-compose if the docker compose command does not work . You may have noticed that this can be quite painful to orchestrate manually the start, stop and rebuild of our containers. Thankfully, a useful tool called docker-compose comes in handy in those situations. 2- Let\u2019s create a docker-compose.yml file with the following structure to define and drive our containers: version : '3.7' services : backend : build : #TODO networks : #TODO depends_on : #TODO database : build : #TODO networks : #TODO httpd : build : #TODO ports : #TODO networks : #TODO depends_on : #TODO networks : my-network : The docker-compose will handle the three containers and a network for us. Once your containers are orchestrated as services by docker-compose you should have a perfectly running application, make sure you can access your API on localhost . Note The ports of both your backend and database should not be opened to your host machine. Tip Why is docker-compose so important? Question 1-3 Document docker-compose most important commands. 1-4 Document your docker-compose file. Check A working 3-tier application running with docker-compose. Publish Your docker images are stored locally, let\u2019s publish them, so they can be used by other team members or on other machines. You will need a Docker Hub account. 1- Connect to your freshly created account with docker login . 2- Tag your image. For now, we have been only using the latest tag, now that we want to publish it, let\u2019s add some meaningful version information to our images. docker tag my-database USERNAME/my-database:1.0 3- Then push your image to dockerhub: docker push USERNAME/my-database Dockerhub is not the only docker image registry, and you can also self-host your images (this is obviously the choice of most companies). Once you publish your images to dockerhub, you will see them in your account: having some documentation for your image would be quite useful if you want to use those later. Question 1-5 Document your publication commands and published images in dockerhub. Tip Why do we put our images into an online repo? \u00a9 Takima 2023","title":"TP part 01 - Docker"},{"location":"ch1-discover-docker-tp/#discover-docker","text":"Check Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time). Question Point to document/report. Tip Interesting information.","title":"Discover Docker"},{"location":"ch1-discover-docker-tp/#goals","text":"","title":"Goals"},{"location":"ch1-discover-docker-tp/#good-practice","text":"Do not forget to document what you do along the steps, the documentation provided will be evaluated as your report. Create an appropriate file structure, 1 folder per image.","title":"Good practice"},{"location":"ch1-discover-docker-tp/#target-application","text":"3-tiers application: HTTP server Backend API Database For each of those applications, we will follow the same process: choose the appropriate docker base image, create and configure this image, put our application specifics inside and at some point have it running. Our final goal is to have a 3-tier web API running.","title":"Target application"},{"location":"ch1-discover-docker-tp/#base-images","text":"HTTP server Backend API Database","title":"Base images"},{"location":"ch1-discover-docker-tp/#database","text":"","title":"Database"},{"location":"ch1-discover-docker-tp/#basics","text":"We will use the image: postgres:14.1-alpine. Let\u2019s have a simple postgres server running, here is what would be a minimal Dockerfile: FROM postgres:14.1-alpine ENV POSTGRES_DB = db \\ POSTGRES_USER = usr \\ POSTGRES_PASSWORD = pwd Build this image and start a container properly, you should be able to access your database depending on the port binding you choose: localhost:PORT. Your Postgres DB should be up and running. Connect to your database and check that everything is running smoothly. Don\u2019t forget to name your docker image and container. Tip If you have difficulties go back to part 2.3.3 Build the image and 2.3.4 Run your image on TD01 - Docker ( TD 1 Discover Docker ). Re-run your database and adminer with --network app-network to enable adminer/database communication. We use -\u2013network instead of -\u2013link because the latter is deprecated. Also, does it seem right to have passwords written in plain text in a file? You may rather define those environment parameters when running the image using the flag -e . Tip Why should we run the container with a flag -e to give the environment variables?","title":"Basics"},{"location":"ch1-discover-docker-tp/#init-database","text":"Tip Don't forget to create your network docker network create app-network It would be nice to have our database structure initialized with the docker image as well as some initial data. Any sql scripts found in /docker-entrypoint-initdb.d will be executed in alphabetical order, therefore let\u2019s add a couple scripts to our image: Tip Don't forget to restart the adminer: docker run \\ -p \"8090:8080\" \\ --net = app-network \\ --name = adminer \\ -d \\ adminer 01-CreateScheme.sql CREATE TABLE public . departments ( id SERIAL PRIMARY KEY , name VARCHAR ( 20 ) NOT NULL ); CREATE TABLE public . students ( id SERIAL PRIMARY KEY , department_id INT NOT NULL REFERENCES departments ( id ), first_name VARCHAR ( 20 ) NOT NULL , last_name VARCHAR ( 20 ) NOT NULL ); 02-InsertData.sql INSERT INTO departments ( name ) VALUES ( 'IRC' ); INSERT INTO departments ( name ) VALUES ( 'ETI' ); INSERT INTO departments ( name ) VALUES ( 'CGP' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 1 , 'Eli' , 'Copter' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 2 , 'Emma' , 'Carena' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 2 , 'Jack' , 'Uzzi' ); INSERT INTO students ( department_id , first_name , last_name ) VALUES ( 3 , 'Aude' , 'Javel' ); Rebuild your image and check that your scripts have been executed at startup and that the data is present in your container. Tip When we talk about /docker-entrypoint-initdb.d it means inside the container, so you have to copy your directory's content and the container\u2019s directory.","title":"Init database"},{"location":"ch1-discover-docker-tp/#persist-data","text":"You may have noticed that if your database container gets destroyed then all your data is reset, a database must persist data durably. Use volumes to persist data on the host disk. -v /my/own/datadir:/var/lib/postgresql/data Check that data survives when your container gets destroyed. Link Docker volumes Tip Why do we need a volume to be attached to our postgres container? Question 1-1 Document your database container essentials: commands and Dockerfile.","title":"Persist data"},{"location":"ch1-discover-docker-tp/#backend-api","text":"","title":"Backend API"},{"location":"ch1-discover-docker-tp/#basics_1","text":"For starters, we will simply run a Java hello-world class in our containers, only after will we be running a jar. In both cases, choose the proper image keeping in mind that we only need a Java runtime . Here is a complex Java Hello World implementation: Main.java public class Main { public static void main ( String [] args ) { System . out . println ( \"Hello World!\" ); } } 1- Compile with your target Java: javac Main.java . 2- Write dockerfile. FROM # TODO: Choose a java JRE # TODO: Add the compiled java (aka bytecode, aka .class) # TODO: Run the Java with: \u201cjava Main\u201d command. 3- Now, to launch app you have to do the same thing that Basic step 1. Here you have a first glimpse of your backend application. In the next step we will simply enrich the build (using maven instead of a minimalistic javac) and execute a jar instead of a simple .class. \u2192 If it\u2019s a success you must see \u201cHello Word\u201d in your console.","title":"Basics"},{"location":"ch1-discover-docker-tp/#multistage-build","text":"In the previous section we were building Java code on our machine to have it running on a docker container. Wouldn\u2019t it be great to have Docker handle the build as well? You probably noticed that the default openjdk docker images contain... Well... a JDK! Create a multistage build using the Multistage . Your Dockerfile should look like this: FROM openjdk:11 # Build Main.java # TODO : in next steps (not now) FROM openjdk:11-jre # Copy resource from previous stage COPY --from = 0 /usr/src/Main.class . # Run java code with the JRE # TODO : in next steps (not now) Don\u2019t fill the Dockerfile now, we will have to do it in the next steps.","title":"Multistage build"},{"location":"ch1-discover-docker-tp/#backend-simple-api","text":"We will deploy a Springboot application providing a simple API with a single greeting endpoint. Create your Springboot application on: Spring Initializer . Use the following config: Project: Maven Language: Java 17 Spring Boot: 2.7.5 Packaging: Jar Dependencies: Spring Web Generate the project and give it a simple GreetingController class: package fr.takima.training.simpleapi.controller ; import org.springframework.web.bind.annotation.* ; import java.util.concurrent.atomic.AtomicLong ; @RestController public class GreetingController { private static final String template = \"Hello, %s!\" ; private final AtomicLong counter = new AtomicLong (); @GetMapping ( \"/\" ) public Greeting greeting ( @RequestParam ( value = \"name\" , defaultValue = \"World\" ) String name ) { return new Greeting ( counter . incrementAndGet (), String . format ( template , name )); } class Greeting { private final long id ; private final String content ; public Greeting ( long id , String content ) { this . id = id ; this . content = content ; } public long getId () { return id ; } public String getContent () { return content ; } } } You can now build and start your application, of course you will need maven and a jdk-17. How convenient would it be to have a virtual container to build and run our simplistic API? Oh wait, we have docker, here is how you could build and run your application with Docker: # Build FROM maven:3.8.6-amazoncorretto-17 AS myapp-build ENV MYAPP_HOME /opt/myapp WORKDIR $MYAPP_HOME COPY pom.xml . COPY src ./src RUN mvn package -DskipTests # Run FROM amazoncorretto:17 ENV MYAPP_HOME /opt/myapp WORKDIR $MYAPP_HOME COPY --from = myapp-build $MYAPP_HOME /target/*.jar $MYAPP_HOME /myapp.jar ENTRYPOINT java -jar myapp.jar Question 1-2 Why do we need a multistage build? And explain each step of this dockerfile. Check A working Springboot application with a simple HelloWorld endpoint. Did you notice that maven downloads all libraries on every image build? You can contribute to saving the planet caching libraries when maven pom file has not been changed by running the goal: mvn dependency:go-offline .","title":"Backend simple api"},{"location":"ch1-discover-docker-tp/#backend-api_1","text":"Let\u2019s now build and run the backend API connected to the database. You can get the zipped source code here: simple-api . Adjust the configuration in simple-api/src/main/resources/application.yml (this is the application configuration). How to access the database container from your backend application? Use the deprecated --link or create a docker network . Once everything is properly bound, you should be able to access your application API, for example on: /departments/IRC/students . [ { \"id\" : 1 , \"firstname\" : \"Eli\" , \"lastname\" : \"Copter\" , \"department\" : { \"id\" : 1 , \"name\" : \"IRC\" } } ] Explore your API other endpoints, have a look at the controllers in the source code. Check A simple web API on top of your database.","title":"Backend API"},{"location":"ch1-discover-docker-tp/#http-server","text":"","title":"Http server"},{"location":"ch1-discover-docker-tp/#basics_2","text":"","title":"Basics"},{"location":"ch1-discover-docker-tp/#choose-an-appropriate-base-image","text":"Create a simple landing page: index.html and put it inside your container. It should be enough for now, start your container and check that everything is working as expected. Here are commands that you may want to try to do so: docker stats docker inspect docker logs Link Httpd Getting Started","title":"Choose an appropriate base image."},{"location":"ch1-discover-docker-tp/#configuration","text":"You are using the default apache configuration, and it will be enough for now, you use yours by copying it in your image. Use docker exec to retrieve this default configuration from your running container /usr/local/apache2/conf/httpd.conf . Note You can also use docker cp .","title":"Configuration"},{"location":"ch1-discover-docker-tp/#reverse-proxy","text":"We will configure the http server as a simple reverse proxy server in front of our application, this server could be used to deliver a front-end application, to configure SSL or to handle load balancing. So this can be quite useful even though in our case we will keep things simple. Here is the documentation: Reverse Proxy . Add the following to the configuration, and you should be all set: ServerName localhost <VirtualHost *:80> ProxyPreserveHost On ProxyPass / http://YOUR_BACKEND_LINK:8080/ ProxyPassReverse / http://YOUR_BACKEND_LINK:8080/ </VirtualHost> Tip Why do we need a reverse proxy? Notes Checkpoint: a working application through a reverse proxy.","title":"Reverse proxy"},{"location":"ch1-discover-docker-tp/#link-application","text":"","title":"Link application"},{"location":"ch1-discover-docker-tp/#docker-compose","text":"1- Install docker-compose if the docker compose command does not work . You may have noticed that this can be quite painful to orchestrate manually the start, stop and rebuild of our containers. Thankfully, a useful tool called docker-compose comes in handy in those situations. 2- Let\u2019s create a docker-compose.yml file with the following structure to define and drive our containers: version : '3.7' services : backend : build : #TODO networks : #TODO depends_on : #TODO database : build : #TODO networks : #TODO httpd : build : #TODO ports : #TODO networks : #TODO depends_on : #TODO networks : my-network : The docker-compose will handle the three containers and a network for us. Once your containers are orchestrated as services by docker-compose you should have a perfectly running application, make sure you can access your API on localhost . Note The ports of both your backend and database should not be opened to your host machine. Tip Why is docker-compose so important? Question 1-3 Document docker-compose most important commands. 1-4 Document your docker-compose file. Check A working 3-tier application running with docker-compose.","title":"Docker-compose"},{"location":"ch1-discover-docker-tp/#publish","text":"Your docker images are stored locally, let\u2019s publish them, so they can be used by other team members or on other machines. You will need a Docker Hub account. 1- Connect to your freshly created account with docker login . 2- Tag your image. For now, we have been only using the latest tag, now that we want to publish it, let\u2019s add some meaningful version information to our images. docker tag my-database USERNAME/my-database:1.0 3- Then push your image to dockerhub: docker push USERNAME/my-database Dockerhub is not the only docker image registry, and you can also self-host your images (this is obviously the choice of most companies). Once you publish your images to dockerhub, you will see them in your account: having some documentation for your image would be quite useful if you want to use those later. Question 1-5 Document your publication commands and published images in dockerhub. Tip Why do we put our images into an online repo? \u00a9 Takima 2023","title":"Publish"},{"location":"ch2-discover-github-actions-td/","text":"Discover Github Note Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time) Question Point to document/report Tip Interesting information Setup Prerequisites Even if it seems pretty usual to use Git in the development world, not every project is managed with this tool. The main goal here is to have you create and set up a Github account before using it for further purposes. Git will be required as well as it is a must have. You might want to start with Sign up to Github First step is (if not already done) to sign up to Github with your school mail address and fill the required information. We recommend you to use an individual free plan for the next steps of this project. You can eventually fill the last page but it\u2019s not really important. Select \u201cComplete setup\u201d. There you are, your (probably not first) Github account is set up. Yay ! Now, let\u2019s move on to the next step ! Project forking and publishing For this part, we are going to fork the project that will be used for the rest of the lesson (I mean, till the end of the week). Now you own the project under your Github workspace, you can basically do whatever you want on this project. However we recommend not to modify the whole java and maven content if you still want this project to compile. First of all, make sure the git CLI is installed on your computer and then clone the project on your computer to be able to modify it locally. Securing Github access There are actually two different ways of cloning and publishing a project. By default, Github will propose you to clone by HTTPS link. Copy to clipboard, then open a new terminal and enter : $ git clone <project_url_with_https> Git will probably ask you to authenticate in order to be able to clone the repository. It will ask you the same thing every time you want to publish your work on a branch. This might be painful and you don\u2019t want to do this. The second option is \u201cuse SSH\u201d and the link starts with \u201cgit@github.com:\u2026\u201d, but there is a prerequisite to use this solution, you\u2019ll need to create an SSH key and have it added to your account. Fine, then tape: $ ssh-keygen -t rsa -b 4096 -f ~/.ssh/ { theNameOfYourKeyPair } It will ask you to enter and confirm a passphrase, this is for security purposes but we will let it empty for this course. Well done, you\u2019ve generated a new RSA key pair of 4096 bits size. If you do \u201cls ~/.ssh\u201d you\u2019ll see new files inside your folder, one is named theNameOfYourKeyPair and the other one theNameOfYourKeyPair.pub. The first one is your private key to NEVER communicate to anyone and the second one is you public key. Let\u2019s take a look to this last one, enter \u201ccat ~/.ssh/theNameOfYourKeyPair.pub\u201d: Something like this will appear on you terminal, this is the content of your public key that you will communicate to Github. Copy the whole content and past it to you Github account under \u201cSettings\u201d and \u201cSSH and GPG keys\u201d. Click on New SSH key and paste the content of your public key. Give it a name and validate the operation. Now try to clone the repository again with the git@ prefix. It will ask you to select a key pair to perform the action. Take the one you\u2019ve just indicated to Github and press enter. Now you are able to clone and publish work on your Github repository without entering a password every time, I hope you enjoy this. Let\u2019s publish Open the project inside your favorite IDE (I hope it\u2019s IntelliJ) and open the file README.md. Modify this file entering, for example \u201cThis project is now mine\u201d. Save it and check that Git has correctly seen you changes $ git status You\u2019ll see you file colored in red. This means that Git has seen you\u2019ve made some modifications to this file, but it will not take them into account once you will publish them. Then ask git to add them to your work. $ git add . Actually, we did not ask him to add our file, but to add any modification made to any file inside our working directory. Now if you enter \u201cgit status\u201d again you\u2019ll see that your file is colored in green. You work will be taken into account, hopefully. Let\u2019s commit this work: $ git commit -m \u201cThe message of your commit\u201d Now if you try to \u201cgit status\u201d again you\u2019ll see that your workspace is \u201cclean\u201d. Git created a new reference with all the changes you\u2019ve made. If you go on and enter: $ git log You\u2019ll see the message of you last commit on top of the references. However you cannot see the changes on the Github website because we did not publish yet our work. Let\u2019s do it ! $ git push origin master This command literally means \u201cI want to publish my work on the distant/remote branch master\u201d. And now you can see that your work is published online ! Big up guys ! Configure your repository Git is one of the most useful tool you\u2019ll find in your developer life. Almost everybody uses it and most of the time you\u2019ll have to work with other people on project using Github. However you\u2019ll find many people that use it wrongly, and many people that will create things you don\u2019t want to merge in you production branch. Let\u2019s secure a bit our labor to prevent any fool to throw it away. Go back to your project on the Github webpage and click on settings. Go to Branches and you\u2019ll see that your default branch is master. Fine, it means that every time you connect on your repository, this branch will be displayed. Just under this indication, you\u2019ll see a Branch protection rule. Try to add one. You\u2019ll see a bunch of options, most of them are very useful working in team (especially asking for pull request and review before merging inside master branch). You can also select options to block push force (when someone does push -f) because it doesn\u2019t take care of Git warning messages that usually prevent you from pushing. As you are working alone on this project we will only add the name \u201cmaster\u201d to the naming pattern and let the rest as it is. It will only prevent you from doing bad things on you master branch. Finally, be aware that all the work you do on Github is public by default. Therefore you should or you must NEVER publish any password on your repository. Thankfully you can turn your repository to private from the options and there are Environment Variables that you can set and secure (I mean encrypt) inside your Github repository under Secrets. Git basic commands Clone a project $ git clone <url_of_the_project> Fetch distant modifications without merging them into your branch $ git fetch -p Fetch distant modifications and merge them into you branch $ git pull Add your changes to the workspace $ git add . Commit your changes $ git commit -m \u201cYour message\u201d Publish your changes $ git push origin <name_of_the_remote_branch>","title":"TD part 02 - Github Actions"},{"location":"ch2-discover-github-actions-td/#discover-github","text":"Note Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time) Question Point to document/report Tip Interesting information","title":"Discover Github"},{"location":"ch2-discover-github-actions-td/#setup","text":"","title":"Setup"},{"location":"ch2-discover-github-actions-td/#prerequisites","text":"Even if it seems pretty usual to use Git in the development world, not every project is managed with this tool. The main goal here is to have you create and set up a Github account before using it for further purposes. Git will be required as well as it is a must have. You might want to start with","title":"Prerequisites"},{"location":"ch2-discover-github-actions-td/#sign-up-to-github","text":"First step is (if not already done) to sign up to Github with your school mail address and fill the required information. We recommend you to use an individual free plan for the next steps of this project. You can eventually fill the last page but it\u2019s not really important. Select \u201cComplete setup\u201d. There you are, your (probably not first) Github account is set up. Yay ! Now, let\u2019s move on to the next step !","title":"Sign up to Github"},{"location":"ch2-discover-github-actions-td/#project-forking-and-publishing","text":"For this part, we are going to fork the project that will be used for the rest of the lesson (I mean, till the end of the week). Now you own the project under your Github workspace, you can basically do whatever you want on this project. However we recommend not to modify the whole java and maven content if you still want this project to compile. First of all, make sure the git CLI is installed on your computer and then clone the project on your computer to be able to modify it locally.","title":"Project forking and publishing"},{"location":"ch2-discover-github-actions-td/#securing-github-access","text":"There are actually two different ways of cloning and publishing a project. By default, Github will propose you to clone by HTTPS link. Copy to clipboard, then open a new terminal and enter : $ git clone <project_url_with_https> Git will probably ask you to authenticate in order to be able to clone the repository. It will ask you the same thing every time you want to publish your work on a branch. This might be painful and you don\u2019t want to do this. The second option is \u201cuse SSH\u201d and the link starts with \u201cgit@github.com:\u2026\u201d, but there is a prerequisite to use this solution, you\u2019ll need to create an SSH key and have it added to your account. Fine, then tape: $ ssh-keygen -t rsa -b 4096 -f ~/.ssh/ { theNameOfYourKeyPair } It will ask you to enter and confirm a passphrase, this is for security purposes but we will let it empty for this course. Well done, you\u2019ve generated a new RSA key pair of 4096 bits size. If you do \u201cls ~/.ssh\u201d you\u2019ll see new files inside your folder, one is named theNameOfYourKeyPair and the other one theNameOfYourKeyPair.pub. The first one is your private key to NEVER communicate to anyone and the second one is you public key. Let\u2019s take a look to this last one, enter \u201ccat ~/.ssh/theNameOfYourKeyPair.pub\u201d: Something like this will appear on you terminal, this is the content of your public key that you will communicate to Github. Copy the whole content and past it to you Github account under \u201cSettings\u201d and \u201cSSH and GPG keys\u201d. Click on New SSH key and paste the content of your public key. Give it a name and validate the operation. Now try to clone the repository again with the git@ prefix. It will ask you to select a key pair to perform the action. Take the one you\u2019ve just indicated to Github and press enter. Now you are able to clone and publish work on your Github repository without entering a password every time, I hope you enjoy this.","title":"Securing Github access"},{"location":"ch2-discover-github-actions-td/#lets-publish","text":"Open the project inside your favorite IDE (I hope it\u2019s IntelliJ) and open the file README.md. Modify this file entering, for example \u201cThis project is now mine\u201d. Save it and check that Git has correctly seen you changes $ git status You\u2019ll see you file colored in red. This means that Git has seen you\u2019ve made some modifications to this file, but it will not take them into account once you will publish them. Then ask git to add them to your work. $ git add . Actually, we did not ask him to add our file, but to add any modification made to any file inside our working directory. Now if you enter \u201cgit status\u201d again you\u2019ll see that your file is colored in green. You work will be taken into account, hopefully. Let\u2019s commit this work: $ git commit -m \u201cThe message of your commit\u201d Now if you try to \u201cgit status\u201d again you\u2019ll see that your workspace is \u201cclean\u201d. Git created a new reference with all the changes you\u2019ve made. If you go on and enter: $ git log You\u2019ll see the message of you last commit on top of the references. However you cannot see the changes on the Github website because we did not publish yet our work. Let\u2019s do it ! $ git push origin master This command literally means \u201cI want to publish my work on the distant/remote branch master\u201d. And now you can see that your work is published online ! Big up guys !","title":"Let\u2019s publish"},{"location":"ch2-discover-github-actions-td/#configure-your-repository","text":"Git is one of the most useful tool you\u2019ll find in your developer life. Almost everybody uses it and most of the time you\u2019ll have to work with other people on project using Github. However you\u2019ll find many people that use it wrongly, and many people that will create things you don\u2019t want to merge in you production branch. Let\u2019s secure a bit our labor to prevent any fool to throw it away. Go back to your project on the Github webpage and click on settings. Go to Branches and you\u2019ll see that your default branch is master. Fine, it means that every time you connect on your repository, this branch will be displayed. Just under this indication, you\u2019ll see a Branch protection rule. Try to add one. You\u2019ll see a bunch of options, most of them are very useful working in team (especially asking for pull request and review before merging inside master branch). You can also select options to block push force (when someone does push -f) because it doesn\u2019t take care of Git warning messages that usually prevent you from pushing. As you are working alone on this project we will only add the name \u201cmaster\u201d to the naming pattern and let the rest as it is. It will only prevent you from doing bad things on you master branch. Finally, be aware that all the work you do on Github is public by default. Therefore you should or you must NEVER publish any password on your repository. Thankfully you can turn your repository to private from the options and there are Environment Variables that you can set and secure (I mean encrypt) inside your Github repository under Secrets.","title":"Configure your repository"},{"location":"ch2-discover-github-actions-td/#git-basic-commands","text":"Clone a project $ git clone <url_of_the_project> Fetch distant modifications without merging them into your branch $ git fetch -p Fetch distant modifications and merge them into you branch $ git pull Add your changes to the workspace $ git add . Commit your changes $ git commit -m \u201cYour message\u201d Publish your changes $ git push origin <name_of_the_remote_branch>","title":"Git basic commands"},{"location":"ch2-discover-github-actions-tp/","text":"Discover Github Action Check Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time) Question Point to document/report Tip Interesting information Goals Good Practice Do not forget to document what you do along the steps. Create an appropriate file structure, 1 folder per image. Target Application Complete pipeline workflow for testing and delivering your software application. We are going to use different useful tools to build your application, test it automatically, and check the code quality at the same time. Link GitHub Actions Setup GitHub Actions The first tool we are going to use is GitHub Actions . GitHub Actions is an online service that allows you to build pipelines to test your application. Keep in mind that GitHub Actions is not the only one on the market to build integration pipelines. Historically many companies were using Jenkins (and still a lot continue to do it), it is way less accessible than GitHub Actions but much more configurable. You will also hear about Gitlab CI and Bitbucket Pipelines during your work life. First steps into the CI World Note Push your previous project on your personal GitHub repository. Most of the CI services use a yaml file (except Jenkins that uses a\u2026 Groovy file\u2026) to describe the expected steps to be done over the pipeline execution. Go on and create your first main.yml file into your project\u2019s root directory. Build and test your Application For those who are not familiar with Maven and Java project structures, here is the command for building and running your tests: mvn clean verify You need to launch this command from your pom.xml directory, or specify the path to it with --file /path/to/pom.xml argument. Note What is it supposed to do? This command will actually clear your previous builds inside your cache (otherwise your can have unexpected behavior because maven did not build again each part of your application), then it will freshly build each module inside your application, and finally it will run both Unit Tests and Integration Tests (sometime called Component Tests as well). Note Unit tests? Component tests? Integration tests require a database to verify you correctly inserted or retrieved data from it. Fortunately for you, we\u2019ve already taken care of this! But you still need to understand how it works under the hood. Take a look at your application file tree. Let\u2019s take a look at the pom.xml that is inside the simple-api , you will find some very helpful dependencies for your testing. <dependencies> <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> ${testcontainers.version} </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> jdbc </artifactId> <version> ${testcontainers.version} </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> postgresql </artifactId> <version> ${testcontainers.version} </version> <scope> test </scope> </dependency> </dependencies> As you can see, there are a bunch of testcontainers dependencies inside the pom. Question 2-1 What are testcontainers? They simply are java libraries that allow you to run a bunch of docker containers while testing. Here we use the postgresql container to attach to our application while testing. If you run the command mvn clean verify you\u2019ll be able to see the following: As you can see, a docker container has been launched while your tests were running, pretty convenient, isn\u2019t it? Finally, you\u2019ll see your test results. Now, it is up to you! Create your first CI, asking to build and test your application every time someone commits and pushes code on the repository. First you create a .github/workflows directory in your repository on GitHub. Put your main.yml inside workflows. The main.yml holds the architecture of your pipeline. Each job will represent a step of what you want to do. Each job will be run in parallel unless a link is specified. Here is what your main.yml should look like: name : CI devops 2023 on : #to begin you want to launch this job in main and develop push : branches : #TODO pull_request : jobs : test-backend : runs-on : ubuntu-22.04 steps : #checkout your github code using actions/checkout@v2.5.0 - uses : actions/checkout@v2.5.0 #do the same with another action (actions/setup-java@v3) that enable to setup jdk 17 - name : Set up JDK 17 #TODO #finally build your app with the latest command - name : Build and test with Maven run : #TODO It\u2019s your turn, fill the #TODOs! To see the result you must follow the next steps: And if it\u2019s GREEN you win! Question 2-2 Document your Github Actions configurations. First steps into the CD World Here we are going to configure the Continuous Delivery of our project. Therefore, the main goal will be to create and save a docker image containing our application on the Docker Hub every time there is a commit on a main branch. As you probably already noticed, you need to log in to docker hub to perform any publication. However, you don\u2019t want to publish your credentials on a public repository (it is not even a good practise to do it on a private repository). Fortunately, GitHub allows you to create secured environment variables. 1- Add your docker hub credentials to the environment variables in GitHub Actions (and let them secured). Note Secured Variables, why? Now that you added them, you can freely declare them and use them inside your GitHub Actions pipeline. 2- Build your docker images inside your GitHub Actions pipeline. Maybe the template Build a docker image can help you! # define job to build and publish docker image build-and-push-docker-image : needs : test-backend # run only when code is compiling and tests are passing runs-on : ubuntu-22.04 # steps to perform in job steps : - name : Checkout code uses : actions/checkout@v2.5.0 - name : Build image and push backend uses : docker/build-push-action@v3 with : # relative path to the place where source code with Dockerfile is located context : ./simple-api # Note: tags has to be all lower-case tags : ${{secrets.DOCKERHUB_USERNAME}}/tp-devops/simple-api - name : Build image and push database # DO the same for database - name : Build image and push httpd # DO the same for httpd Note Why did we put needs: build-and-test-backend on this job? Maybe try without this and you will see! OK your images are built but not yet published on dockerhub . 3- Publish your docker images when there is a commit on the main branch. Don\u2019t forget to do a docker login and to put your credentials on secrets! - name : Login to DockerHub run : docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKERHUB_TOKEN }} And after modify job Build image and push backend to add a push action: - name : Build image and push backend uses : docker/build-push-action@v3 with : # relative path to the place where source code with Dockerfile is located context : ./simple-api # Note: tags has to be all lower-case tags : ${{secrets.DOCKERHUB_USERNAME}}/tp-devops:simple-api # build on feature branches, push only on main branch push : ${{ github.ref == 'refs/heads/main' }} Do the same for other containers. Note For what purpose do we need to push docker images? Now you should be able to find your docker images on your docker repository. Check Working CI & Docker images pushed to your repository. Setup Quality Gate What is quality about? Quality is here to make sure your code will be maintainable and determine every unsecured block. It helps you produce better and tested features, and it will also prevent having dirty code pushed inside your main branch. For this purpose, we are going to use SonarCloud , a cloud solution that makes analysis and reports of your code. This is a useful tool that everyone should use in order to learn java best practices. Register to SonarCloud Create your free-tier account on SonarCloud . SonarCloud will propose you to set up your GitHub Actions pipeline from the GitHub Actions , but forget about that, there is a much better way to save the SonarCloud provided and provide it into your main.yml . 1- You must create an organization. 2- And keep the project key and the organization key you will need it later. 3- You need to add this script to your main.yml for launch sonar at each commit. Set up your pipeline to use SonarCloud analysis while testing. For that, you need to modify your first step named Build and test with Maven and change sonar organization and project key. mvn -B verify sonar:sonar -Dsonar.projectKey = devops-2023 -Dsonar.organization = devops-school -Dsonar.host.url = https://sonarcloud.io -Dsonar.login = ${ { secrets.SONAR_TOKEN } } --file ./simple-api/pom.xml If you did your configuration correctly, you should be able to see the SonarCloud analysis report online: Check Working quality gate. Question Document your quality gate configuration. Well done buddies, you\u2019ve created your very first Quality Gate! Yay! Bonus: split pipelines (Optional) In this step you have to separate your jobs into different workflows so that they respect 2 things: test-backend must be launched on develop and master branch and build-and-push-docker-image on master only. The job that pushes the docker api image must be launched only if test-backend is passed. Tip You can use on: workflow_run to trigger a workflow when another workflow is passed. \u00a9 Takima 2023","title":"TP part 02 - Github Actions"},{"location":"ch2-discover-github-actions-tp/#discover-github-action","text":"Check Checkpoint: call us to check your results (don\u2019t stay blocked on a checkpoint if we are busy, we can check \u2154 checkpoints at the same time) Question Point to document/report Tip Interesting information","title":"Discover Github Action"},{"location":"ch2-discover-github-actions-tp/#goals","text":"","title":"Goals"},{"location":"ch2-discover-github-actions-tp/#good-practice","text":"Do not forget to document what you do along the steps. Create an appropriate file structure, 1 folder per image.","title":"Good Practice"},{"location":"ch2-discover-github-actions-tp/#target-application","text":"Complete pipeline workflow for testing and delivering your software application. We are going to use different useful tools to build your application, test it automatically, and check the code quality at the same time. Link GitHub Actions","title":"Target Application"},{"location":"ch2-discover-github-actions-tp/#setup-github-actions","text":"The first tool we are going to use is GitHub Actions . GitHub Actions is an online service that allows you to build pipelines to test your application. Keep in mind that GitHub Actions is not the only one on the market to build integration pipelines. Historically many companies were using Jenkins (and still a lot continue to do it), it is way less accessible than GitHub Actions but much more configurable. You will also hear about Gitlab CI and Bitbucket Pipelines during your work life.","title":"Setup GitHub Actions"},{"location":"ch2-discover-github-actions-tp/#first-steps-into-the-ci-world","text":"Note Push your previous project on your personal GitHub repository. Most of the CI services use a yaml file (except Jenkins that uses a\u2026 Groovy file\u2026) to describe the expected steps to be done over the pipeline execution. Go on and create your first main.yml file into your project\u2019s root directory.","title":"First steps into the CI World"},{"location":"ch2-discover-github-actions-tp/#build-and-test-your-application","text":"For those who are not familiar with Maven and Java project structures, here is the command for building and running your tests: mvn clean verify You need to launch this command from your pom.xml directory, or specify the path to it with --file /path/to/pom.xml argument. Note What is it supposed to do? This command will actually clear your previous builds inside your cache (otherwise your can have unexpected behavior because maven did not build again each part of your application), then it will freshly build each module inside your application, and finally it will run both Unit Tests and Integration Tests (sometime called Component Tests as well). Note Unit tests? Component tests? Integration tests require a database to verify you correctly inserted or retrieved data from it. Fortunately for you, we\u2019ve already taken care of this! But you still need to understand how it works under the hood. Take a look at your application file tree. Let\u2019s take a look at the pom.xml that is inside the simple-api , you will find some very helpful dependencies for your testing. <dependencies> <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> ${testcontainers.version} </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> jdbc </artifactId> <version> ${testcontainers.version} </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> postgresql </artifactId> <version> ${testcontainers.version} </version> <scope> test </scope> </dependency> </dependencies> As you can see, there are a bunch of testcontainers dependencies inside the pom. Question 2-1 What are testcontainers? They simply are java libraries that allow you to run a bunch of docker containers while testing. Here we use the postgresql container to attach to our application while testing. If you run the command mvn clean verify you\u2019ll be able to see the following: As you can see, a docker container has been launched while your tests were running, pretty convenient, isn\u2019t it? Finally, you\u2019ll see your test results. Now, it is up to you! Create your first CI, asking to build and test your application every time someone commits and pushes code on the repository. First you create a .github/workflows directory in your repository on GitHub. Put your main.yml inside workflows. The main.yml holds the architecture of your pipeline. Each job will represent a step of what you want to do. Each job will be run in parallel unless a link is specified. Here is what your main.yml should look like: name : CI devops 2023 on : #to begin you want to launch this job in main and develop push : branches : #TODO pull_request : jobs : test-backend : runs-on : ubuntu-22.04 steps : #checkout your github code using actions/checkout@v2.5.0 - uses : actions/checkout@v2.5.0 #do the same with another action (actions/setup-java@v3) that enable to setup jdk 17 - name : Set up JDK 17 #TODO #finally build your app with the latest command - name : Build and test with Maven run : #TODO It\u2019s your turn, fill the #TODOs! To see the result you must follow the next steps: And if it\u2019s GREEN you win! Question 2-2 Document your Github Actions configurations.","title":"Build and test your Application"},{"location":"ch2-discover-github-actions-tp/#first-steps-into-the-cd-world","text":"Here we are going to configure the Continuous Delivery of our project. Therefore, the main goal will be to create and save a docker image containing our application on the Docker Hub every time there is a commit on a main branch. As you probably already noticed, you need to log in to docker hub to perform any publication. However, you don\u2019t want to publish your credentials on a public repository (it is not even a good practise to do it on a private repository). Fortunately, GitHub allows you to create secured environment variables. 1- Add your docker hub credentials to the environment variables in GitHub Actions (and let them secured). Note Secured Variables, why? Now that you added them, you can freely declare them and use them inside your GitHub Actions pipeline. 2- Build your docker images inside your GitHub Actions pipeline. Maybe the template Build a docker image can help you! # define job to build and publish docker image build-and-push-docker-image : needs : test-backend # run only when code is compiling and tests are passing runs-on : ubuntu-22.04 # steps to perform in job steps : - name : Checkout code uses : actions/checkout@v2.5.0 - name : Build image and push backend uses : docker/build-push-action@v3 with : # relative path to the place where source code with Dockerfile is located context : ./simple-api # Note: tags has to be all lower-case tags : ${{secrets.DOCKERHUB_USERNAME}}/tp-devops/simple-api - name : Build image and push database # DO the same for database - name : Build image and push httpd # DO the same for httpd Note Why did we put needs: build-and-test-backend on this job? Maybe try without this and you will see! OK your images are built but not yet published on dockerhub . 3- Publish your docker images when there is a commit on the main branch. Don\u2019t forget to do a docker login and to put your credentials on secrets! - name : Login to DockerHub run : docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKERHUB_TOKEN }} And after modify job Build image and push backend to add a push action: - name : Build image and push backend uses : docker/build-push-action@v3 with : # relative path to the place where source code with Dockerfile is located context : ./simple-api # Note: tags has to be all lower-case tags : ${{secrets.DOCKERHUB_USERNAME}}/tp-devops:simple-api # build on feature branches, push only on main branch push : ${{ github.ref == 'refs/heads/main' }} Do the same for other containers. Note For what purpose do we need to push docker images? Now you should be able to find your docker images on your docker repository. Check Working CI & Docker images pushed to your repository.","title":"First steps into the CD World"},{"location":"ch2-discover-github-actions-tp/#setup-quality-gate","text":"","title":"Setup Quality Gate"},{"location":"ch2-discover-github-actions-tp/#what-is-quality-about","text":"Quality is here to make sure your code will be maintainable and determine every unsecured block. It helps you produce better and tested features, and it will also prevent having dirty code pushed inside your main branch. For this purpose, we are going to use SonarCloud , a cloud solution that makes analysis and reports of your code. This is a useful tool that everyone should use in order to learn java best practices.","title":"What is quality about?"},{"location":"ch2-discover-github-actions-tp/#register-to-sonarcloud","text":"Create your free-tier account on SonarCloud . SonarCloud will propose you to set up your GitHub Actions pipeline from the GitHub Actions , but forget about that, there is a much better way to save the SonarCloud provided and provide it into your main.yml . 1- You must create an organization. 2- And keep the project key and the organization key you will need it later. 3- You need to add this script to your main.yml for launch sonar at each commit. Set up your pipeline to use SonarCloud analysis while testing. For that, you need to modify your first step named Build and test with Maven and change sonar organization and project key. mvn -B verify sonar:sonar -Dsonar.projectKey = devops-2023 -Dsonar.organization = devops-school -Dsonar.host.url = https://sonarcloud.io -Dsonar.login = ${ { secrets.SONAR_TOKEN } } --file ./simple-api/pom.xml If you did your configuration correctly, you should be able to see the SonarCloud analysis report online: Check Working quality gate. Question Document your quality gate configuration. Well done buddies, you\u2019ve created your very first Quality Gate! Yay!","title":"Register to SonarCloud"},{"location":"ch2-discover-github-actions-tp/#bonus-split-pipelines-optional","text":"In this step you have to separate your jobs into different workflows so that they respect 2 things: test-backend must be launched on develop and master branch and build-and-push-docker-image on master only. The job that pushes the docker api image must be launched only if test-backend is passed. Tip You can use on: workflow_run to trigger a workflow when another workflow is passed. \u00a9 Takima 2023","title":"Bonus: split pipelines (Optional)"},{"location":"cheatsheet/","text":"Cheatsheet Docker & docker-compose","title":"Cheatsheet"},{"location":"cheatsheet/#cheatsheet","text":"","title":"Cheatsheet"},{"location":"cheatsheet/#docker-docker-compose","text":"","title":"Docker &amp; docker-compose"}]}